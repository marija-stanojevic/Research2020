# Research2020
 Capstone project at Temple University,Spring 2020
The goal of this paper is to summarize methodologies used in extracting entities and topics from a database of criminal records and a database of articles from the newspaper. Statistical models had successfully been used in studying the topics of roughly 300.000 New York Times articles, and these models had also successfully analyzed entities related to persons, organizations, and places (D Newman, 2006). Additionally, analytical approaches, especially in hotspot mapping, were used in some researches with the aim to predict crime locations and circumstances in the future with decent successes (S. Chainey,2008). Based on the two above notions, this research was performed with the intention to apply data science techniques in analyzing a big amount of data, selecting valuable intelligence and clustering violations depend on their crime types, and in advance creating a crime graph changes by time.  In the research, the plan was to download criminal datasets from Kaggle and from a collection of articles from both Kaggle and from public newspaper websites, and then connecting these datasets into one general dataset, and then to perform statistical and natural language processing methods to extract entities and topics as well as to group similar data point into correct cluster. 
